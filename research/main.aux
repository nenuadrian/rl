\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global/global}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Research Questions}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Maximum Likelihood and Maximum a Posteriori}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{EM Lower Bound}{4}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{EM Iterations}{4}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{EM-Style Policy Iteration vs Policy Gradients}{4}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{EM-style policy iteration (distribution-space then projection).}{5}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}PPO}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Policy Gradient Foundation}{5}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Clipped Surrogate Objective}{6}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Value Function and Entropy}{6}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Full Objective}{6}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Generalised Advantage Estimation (GAE)}{6}{section*.11}\protected@file@percent }
\abx@aux@cite{0}{song2019vmpoonpolicymaximumposteriori}
\abx@aux@segm{0}{0}{song2019vmpoonpolicymaximumposteriori}
\@writefile{toc}{\contentsline {subsection}{Sequence-Level PPO (LLM Case)}{7}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}V-MPO}{7}{section.5}\protected@file@percent }
\abx@aux@page{1}{7}
\@writefile{toc}{\contentsline {subsection}{Implementation}{7}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Policy Evaluation (Critic Update)}{8}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Policy Improvement via EM}{8}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{E-Step: Non-Parametric Policy Construction}{8}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{M-Step: Parametric Projection with KL Constraint}{9}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}EM for Fine-Tuning and LLM-Scale Adaptive Temperature}{9}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{E-step / M-step for SFT}{9}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{E-step / M-step for RL Fine-Tuning (KL-Regularised)}{10}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Token-Level Form}{10}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Sequence-Level V-MPO at LLM Scale}{10}{section*.22}\protected@file@percent }
\newlabel{eq:seq_estep_weights}{{4}{11}{Sequence-Level V-MPO at LLM Scale}{equation.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dual Objective for the Temperature}{11}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerically Stable Log-Sum-Exp Form}{11}{section*.24}\protected@file@percent }
\abx@aux@cite{0}{he2025directadvantageregressionaligning}
\abx@aux@segm{0}{0}{he2025directadvantageregressionaligning}
\@writefile{toc}{\contentsline {subsubsection}{Top-$k$ Selection}{12}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Positive Parameterisation of the Temperature}{12}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Sequence-Level M-Step}{12}{section*.27}\protected@file@percent }
\newlabel{eq:seq_weighted_mstep}{{5}{12}{Sequence-Level M-Step}{equation.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Direct Advantage Regression: Aligning LLMs with Online AI Reward}{12}{section.7}\protected@file@percent }
\abx@aux@page{2}{12}
\@writefile{toc}{\contentsline {subsection}{RL Fine-tuning}{12}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Advantage Weighted Regression}{13}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Direct Advantage Regression}{13}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dual-Constrained Objective}{13}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Theorem.}{13}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Proof.}{14}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Mapping \textsc  {DAR} to V-MPO}{15}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DAR closed-form target.}{15}{section*.35}\protected@file@percent }
\newlabel{eq:dar_opt}{{7}{15}{DAR closed-form target}{equation.7}{}}
\newlabel{eq:dar_log}{{8}{15}{DAR closed-form target}{equation.8}{}}
\@writefile{toc}{\contentsline {paragraph}{V-MPO canonical target.}{15}{section*.36}\protected@file@percent }
\newlabel{eq:vmpo_form}{{9}{15}{V-MPO canonical target}{equation.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Special case 1: identical reference and sampling policies.}{16}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Special case 2: \(\alpha \rightarrow 0\) (reference KL vanishes).}{16}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Algebraic equivalence (log-space explanation).}{16}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical consequences and distinctions.}{16}{section*.40}\protected@file@percent }
\abx@aux@cite{0}{song2019vmpoonpolicymaximumposteriori}
\abx@aux@segm{0}{0}{song2019vmpoonpolicymaximumposteriori}
\abx@aux@cite{0}{dai2019transformerxlattentivelanguagemodels}
\abx@aux@segm{0}{0}{dai2019transformerxlattentivelanguagemodels}
\abx@aux@cite{0}{parisotto2019stabilizingtransformersreinforcementlearning}
\abx@aux@segm{0}{0}{parisotto2019stabilizingtransformersreinforcementlearning}
\abx@aux@cite{0}{song2019vmpoonpolicymaximumposteriori}
\abx@aux@segm{0}{0}{song2019vmpoonpolicymaximumposteriori}
\abx@aux@cite{0}{parisotto2019stabilizingtransformersreinforcementlearning}
\abx@aux@segm{0}{0}{parisotto2019stabilizingtransformersreinforcementlearning}
\@writefile{toc}{\contentsline {paragraph}{Bridge to the EM LLM-scale procedure.}{17}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sequence-level weighted loss (common form).}{17}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Transformers - TrXL}{17}{section.8}\protected@file@percent }
\abx@aux@page{3}{17}
\abx@aux@page{4}{17}
\abx@aux@page{5}{17}
\@writefile{toc}{\contentsline {subsection}{Implementation}{17}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{GTrXL with V-MPO}{18}{section*.44}\protected@file@percent }
\abx@aux@page{6}{18}
\abx@aux@page{7}{18}
\@writefile{toc}{\contentsline {subsubsection}{Identity Map Reordering (TrXL-I)}{18}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gating Layers}{18}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Why GTrXL Suits V-MPO}{18}{section*.47}\protected@file@percent }
\abx@aux@cite{0}{srivastava2014dropout}
\abx@aux@segm{0}{0}{srivastava2014dropout}
\@writefile{toc}{\contentsline {subsubsection}{Architecture and Training Configuration}{19}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}The Case for Dropout}{19}{section.9}\protected@file@percent }
\abx@aux@page{8}{19}
\@writefile{toc}{\contentsline {subsection}{Why PPO Disables Dropout}{19}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Problem 1: stochastic numerator.}{20}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Problem 2: inconsistent denominator.}{20}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Problem 3: KL penalty corruption.}{20}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Why V-MPO / EM-Style Methods Are Dropout-Compatible}{20}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{E-step: weights from advantages, not ratios.}{20}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{M-step: standard cross-entropy.}{21}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{No ratio, no conflict.}{21}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Practical Implications}{21}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}References}{21}{section.10}\protected@file@percent }
\abx@aux@page{9}{21}
\abx@aux@page{10}{22}
\abx@aux@page{11}{22}
\abx@aux@page{12}{22}
\abx@aux@page{13}{22}
\abx@aux@read@bbl@mdfivesum{2299AA748EA8816DDF4755AA9935410E}
\abx@aux@defaultrefcontext{0}{dai2019transformerxlattentivelanguagemodels}{nyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{he2025directadvantageregressionaligning}{nyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{parisotto2019stabilizingtransformersreinforcementlearning}{nyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{song2019vmpoonpolicymaximumposteriori}{nyt/global//global/global/global}
\abx@aux@defaultrefcontext{0}{srivastava2014dropout}{nyt/global//global/global/global}
\gdef \@abspage@last{22}
